{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain \n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(temperature=1, model_name=\"mixtral-8x7b-32768\",groq_api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    I have a pandas dataframe data of PM2.5 and PM10. The columns are 'Timestamp', 'station', 'PM2.5', 'PM10', 'address', 'city', 'latitude', 'longitude',and 'state'. Frequency of data is daily. \n",
    "    I have a geopandas dataframe india of Indian states. The columns are 'state', 'geometry'.\n",
    "\n",
    "    Given this query from user : Categorize them between 'Theoretical', 'Aggregation Bases', 'Visualisation Based', 'Unanswerable'\n",
    "\n",
    "    1. Theoretical : It asks for standard questions based on environment, pollution, health, etc.\n",
    "    2. Aggregation Based : It asks for aggregation of data based on different parameters.\n",
    "    3. Visualisation Based : It asks or requires for visualisation of data based on different parameters.\n",
    "    4. Unanswerable : It is not possible to answer the query, because the query is not related to environment.\n",
    "\n",
    "    Query : {Query}\n",
    "    Category : \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=template, input_variables=[\"Query\"], output_variables=[\"Category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    I have a pandas dataframe data of PM2.5 and PM10. The columns are 'Timestamp', 'station', 'PM2.5', 'PM10', 'address', 'city', 'latitude', 'longitude',and 'state'. Frequency of data is daily. \n",
      "    I have a geopandas dataframe india of Indian states. The columns are 'state', 'geometry'.\n",
      "\n",
      "    Given this query from user : Categorize them between 'Theoretical', 'Aggregation Bases', 'Visualisation Based', 'Unanswerable'\n",
      "\n",
      "    1. Theoretical : It asks for standard questions based on environment, pollution, health, etc.\n",
      "    2. Aggregation Based : It asks for aggregation of data based on different parameters.\n",
      "    3. Visualisation Based : It asks or requires for visualisation of data based on different parameters.\n",
      "    4. Unanswerable : It is not possible to answer the query, because the query is not related to environment.\n",
      "\n",
      "    Query : Can you forecast PM2.5 for next 5 days for Delhi?\n",
      "    Category : \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "Query = \"Can you forecast PM2.5 for next 5 days for Delhi?\"\n",
    "msg = llm_chain(Query)\n",
    "Category = msg['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Visualisation Based'"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_code = ChatGroq(temperature = 1, model_name=\"llama3-70b-8192\",groq_api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Template for Langchain \n",
    "template = \"\"\"\n",
    "    I have a pandas dataframe data of PM2.5 and PM10. The columns are 'Timestamp', 'station', 'PM2.5', 'PM10', 'address', 'city', 'latitude', 'longitude',and 'state'. Frequency of data is daily. Sample data is as follows:\n",
    "        Timestamp\tstation\tPM2.5\tPM10\taddress\tcity\tlatitude\tlongitude\tstate\n",
    "    0\t2017-01-01\t32Bungalows, Bhilai - CECB\tNaN\tNaN\tBhilai RO Office, 5, 32 Bungalows, Bhilai, Dis...\tBhilai\t21.194815\t81.314770\tChhattisgarh\n",
    "    1\t2017-01-01\tAIIMS, Raipur - CECB\tNaN\tNaN\tAll India Institute Of Medical Science, Gate N...\tRaipur\t21.258815\t81.578979\tChhattisgarh\n",
    "    2\t2017-01-01\tBhatagaon New ISBT, Raipur - CECB\tNaN\tNaN\tBhatagaon Interstate New Bus Stand, Raipur, Ch...\tRaipur\t21.219665\t81.630094\tChhattisgarh\n",
    "    3\t2017-01-01\tCivic Center, Bhilai - Bhilai Steel Plant\tNaN\tNaN\tBack Side of Nehru Art Gallery, Civic center, ...\tBhilai\t21.185571\t81.343175\tChhattisgarh\n",
    "    4\t2017-01-01\tGovt. Higher Secondary School, Milupara - CECB\tNaN\tNaN\tGovt. Higher Secondary School, Tamnar, Dist - ...\tMilupara\t22.191017\t83.519701\tChhattisgarh\n",
    "    \n",
    "    I have a geopandas dataframe india of Indian states. The columns are 'ST_NM', 'geometry'. Sample data is as follows:\n",
    "            ST_NM\t    geometry\n",
    "    0\tArunachal Pradesh\tPOLYGON ((95.23392 26.68246, 95.23282 26.70579...\n",
    "    1\tAssam\tPOLYGON ((95.19465 27.03132, 95.15008 26.99934...\n",
    "    2\tChandigarh\tPOLYGON ((76.83806 30.75487, 76.83301 30.73887...\n",
    "    3\tKarnataka\tPOLYGON ((77.55144 18.29191, 77.57026 18.29252...\n",
    "    4\tManipur\tPOLYGON ((94.67545 25.44561, 94.67293 25.42398...\n",
    "    \n",
    "    Given this query from user : {Query}, categorized as {Category}\n",
    "\n",
    "    -> In each category Don't print anything, but save result in a variable `answer` and make it global.\n",
    "    1. If the query belongs to 'Theoretical' category, then :\n",
    "        a) Generate an appropriate answer corresponding to the query. \n",
    "        b) Save the answer in the global variable named 'answer'\n",
    "        c) Use print() function to print the answer.\n",
    "        Example: answer = \"Full form of PM2.5 is Particulate Matter 2.5 micrometers or less in diameter\"\n",
    "    2. If the query belongs to 'Aggregation Based' category, then :\n",
    "        a) Generate an appropriate code. \n",
    "        b) The code should aggregate the data based on different parameters\n",
    "        c) Report the standard deviation, standard error and the number of data points for that aggregation. \n",
    "        d) Report the answer rounded to 2 decimal places with units. \n",
    "        e) Use libraries pandas, numpy.\n",
    "        f) Example: 'The city is Mumbai'\n",
    "    3. If the query belongs to 'Visualisation Based' category, then :\n",
    "        a) Generate an appropriate code.\n",
    "        b) Decide the most appropriate plot(if not specified in the query) to be generated. \n",
    "        c) Mark Indian and WHO guidelines in the plot.\n",
    "        d) Use libraries pandas, matplotlib, geopandas, uuid, openair, darts.\n",
    "        e) Make it in tight layout, save it and save path in global variable answer. \n",
    "        f) Example: `answer='plot.png'`. Use uuid to save the plot.\n",
    "    4. If the query belongs to 'Unanswerable' category, then :\n",
    "        a) Generate a apology message, explaining the reason that this chatbot can primarily answer environment-related queries.\n",
    "        b) Save the answer in the global variable named 'answer'\n",
    "        c) Use print() function to print the answer.\n",
    "\n",
    "  \n",
    "    Use the following code sample to get started:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import uuid\n",
    "\n",
    "df = pd.read_csv(\"Data.csv\")\n",
    "df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"])\n",
    "\n",
    "india = gpd.read_file(\"https://gist.githubusercontent.com/jbrobst/56c13bbbf9d97d187fea01ca62ea5112/raw/e388c4cae20aa53cb5090210a42ebb9b765c0a36/india_states.geojson\")\n",
    "india.loc[india['ST_NM'].isin(['Ladakh', 'Jammu & Kashmir']), 'ST_NM'] = 'Jammu and Kashmir'\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=template, input_variables=[\"Query\",\"Category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    I have a pandas dataframe data of PM2.5 and PM10. The columns are 'Timestamp', 'station', 'PM2.5', 'PM10', 'address', 'city', 'latitude', 'longitude',and 'state'. Frequency of data is daily. Sample data is as follows:\n",
      "        Timestamp\tstation\tPM2.5\tPM10\taddress\tcity\tlatitude\tlongitude\tstate\n",
      "    0\t2017-01-01\t32Bungalows, Bhilai - CECB\tNaN\tNaN\tBhilai RO Office, 5, 32 Bungalows, Bhilai, Dis...\tBhilai\t21.194815\t81.314770\tChhattisgarh\n",
      "    1\t2017-01-01\tAIIMS, Raipur - CECB\tNaN\tNaN\tAll India Institute Of Medical Science, Gate N...\tRaipur\t21.258815\t81.578979\tChhattisgarh\n",
      "    2\t2017-01-01\tBhatagaon New ISBT, Raipur - CECB\tNaN\tNaN\tBhatagaon Interstate New Bus Stand, Raipur, Ch...\tRaipur\t21.219665\t81.630094\tChhattisgarh\n",
      "    3\t2017-01-01\tCivic Center, Bhilai - Bhilai Steel Plant\tNaN\tNaN\tBack Side of Nehru Art Gallery, Civic center, ...\tBhilai\t21.185571\t81.343175\tChhattisgarh\n",
      "    4\t2017-01-01\tGovt. Higher Secondary School, Milupara - CECB\tNaN\tNaN\tGovt. Higher Secondary School, Tamnar, Dist - ...\tMilupara\t22.191017\t83.519701\tChhattisgarh\n",
      "    \n",
      "    I have a geopandas dataframe india of Indian states. The columns are 'ST_NM', 'geometry'. Sample data is as follows:\n",
      "            ST_NM\t    geometry\n",
      "    0\tArunachal Pradesh\tPOLYGON ((95.23392 26.68246, 95.23282 26.70579...\n",
      "    1\tAssam\tPOLYGON ((95.19465 27.03132, 95.15008 26.99934...\n",
      "    2\tChandigarh\tPOLYGON ((76.83806 30.75487, 76.83301 30.73887...\n",
      "    3\tKarnataka\tPOLYGON ((77.55144 18.29191, 77.57026 18.29252...\n",
      "    4\tManipur\tPOLYGON ((94.67545 25.44561, 94.67293 25.42398...\n",
      "    \n",
      "    Given this query from user : Can you forecast PM2.5 for next 5 days for Delhi?, categorized as The categorization for the query \"Can you forecast PM2.5 for next 5 days for Delhi?\" would be 'Theoretical'. This is because the query is asking for a prediction or forecast of PM2.5 values, which is a standard question based on environmental data and pollution. It does not involve any aggregation or visualization of data.\n",
      "\n",
      "    -> In each category Don't print anything, but save result in a variable `answer` and make it global.\n",
      "    1. If the query belongs to 'Theoretical' category, then :\n",
      "        a) Generate an appropriate answer corresponding to the query. \n",
      "        b) Save the answer in the global variable named 'answer'\n",
      "        c) Use print() function to print the answer.\n",
      "        Example: answer = \"Full form of PM2.5 is Particulate Matter 2.5 micrometers or less in diameter\"\n",
      "    2. If the query belongs to 'Aggregation Based' category, then :\n",
      "        a) Generate an appropriate code. \n",
      "        b) The code should aggregate the data based on different parameters\n",
      "        c) Report the standard deviation, standard error and the number of data points for that aggregation. \n",
      "        d) Report the answer rounded to 2 decimal places with units. \n",
      "        e) Use libraries pandas, numpy.\n",
      "        f) Example: 'The city is Mumbai'\n",
      "    3. If the query belongs to 'Visualisation Based' category, then :\n",
      "        a) Generate an appropriate code.\n",
      "        b) Decide the most appropriate plot(if not specified in the query) to be generated. \n",
      "        c) Mark Indian and WHO guidelines in the plot.\n",
      "        d) Use libraries pandas, matplotlib, geopandas, uuid, openair, darts.\n",
      "        e) Make it in tight layout, save it and save path in global variable answer. \n",
      "        f) Example: `answer='plot.png'`. Use uuid to save the plot.\n",
      "    4. If the query belongs to 'Unanswerable' category, then :\n",
      "        a) Generate a apology message, explaining the reason that this chatbot can primarily answer environment-related queries.\n",
      "        b) Save the answer in the global variable named 'answer'\n",
      "        c) Use print() function to print the answer.\n",
      "\n",
      "  \n",
      "    Use the following code sample to get started:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import geopandas as gpd\n",
      "import uuid\n",
      "\n",
      "df = pd.read_csv(\"Data.csv\")\n",
      "df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"])\n",
      "\n",
      "india = gpd.read_file(\"https://gist.githubusercontent.com/jbrobst/56c13bbbf9d97d187fea01ca62ea5112/raw/e388c4cae20aa53cb5090210a42ebb9b765c0a36/india_states.geojson\")\n",
      "india.loc[india['ST_NM'].isin(['Ladakh', 'Jammu & Kashmir']), 'ST_NM'] = 'Jammu and Kashmir'\n",
      "```\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "msg = llm_chain({\"Query\": Query, \"Category\": Category})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since the query belongs to the 'Theoretical' category, we will generate a forecast for PM2. time-series data for Delhi. We can use a time-series forecasting algorithm like ARIMA or Prophet to do this. However, since the data does not have any PM2.5 readings for Delhi, we can't make a specific forecast for Delhi.\n",
      "\n",
      "Instead, we can generate a forecast for a hypothetical PM2.5 time-series dataset for Delhi.\n",
      "A common way to forecast time series data is by using the ARIMA (AutoRegressive Integrated Moving Average) algorithm. We can use the `pmdarima` package to make it easier to work with.\n",
      "\n",
      "First, we need to create a synthetic PM2.5 time series for Delhi. We'39;ll use numpy's random module to create some random variation.\n",
      "\n",
      "```python\n",
      "import pmdarima as pm\n",
      "import numpy as np\n",
      "from datetime import datetime\n",
      "\n",
      "# Create a synthetic PM2. order to create the synthetic time series\n",
      "n_days = 1825 # length of the time series (days)\n",
      "start = datetime(2019, 1, 1) # start date\n",
      "delta = 86400 # seconds per day\n",
      "timestamps = [start + datetime.timedelta(seconds=delta * idx) for idx in range(n_days)]\n",
      "pm25 = 30 + 10 * np.random.rand(n_days) # synthetic PM2.5 readings\n",
      "\n",
      "# Create a DataFrame with Date-time and PM25 data\n",
      "df_delhi = pd.DataFrame({'Timestamp': timestamps, 'PM25': pm25})\n",
      "```\n",
      "\n",
      "Now, we can create a dictionary with the Delhi station name and its `geometry` (to be able to join it with the `india` dataset). We will set the geometry to NaN since it doesn'00;t matter in this case.\n",
      "\n",
      "```python\n",
      "station_geom = {\n",
      "  'Address': 'Delhi',\n",
      "  'geometry': None\n",
      "}\n",
      "```\n",
      "\n",
      "Now, we can create a new DataFrame with the synthetic PM2.5 readings and add the `station_geom` to it.\n",
      "```python\n",
      "  \n",
      "df_delhi = pd.concat([df_delhi, pd.DataFrame(station_geom, index=[0])], ignore_index=True)\n",
      "```\n",
      "\n",
      "Now we can start the ARI order to create the synthetic time series\n",
      "\n",
      "```python\n",
      "# Fit an ARIMA(0,1,1) model to the synthetic PM2.5 dataset\n",
      "model = pm.auto_arima(df_delchi['PM25'].values, start_p=0, start_q=1, max_p=2, max_q=2, m=12)\n",
      "\n",
      "# Create a new column in the dataframe with the forecasted PM2.5 values\n",
      "df_delhi['PM25_forecast'] = np.nan\n",
      "\n",
      "# Generate the next 5 days of PM2.5 forecasts\n",
      "for idx in range(5):\n",
      "  fcast = model.predict(n_periods=1)\n",
      "  df_delhi.loc[len(df_delhi)-1, 'PM2.5_forecast'] = fcast\n",
      "  df_delhi.loc[len(df_global)-1, 'Timestamp'] = dt.datetime.now() + dt.timedelta(days=idx)\n",
      "\n",
      "# Display the PM2.5 forecasts\n",
      "print(df_delhi.tail(8))\n",
      "```\n",
      "\n",
      "While this is a synthetic PM2.5 time series, it demonstrates the process of retrieving the data, forecasting PM2.5 for Delhi, and printing the forecast. In a real-world scenario, you would simply replace the synthetic PM2.5 time series and its processing with the real-world PM2.5 time series for Delhi. Since we do not have one, I have shown this approach using a synthetic dataset.\n",
      "\n",
      "I will store the result in a global variable named 'answer'.\n",
      "\n",
      "```py\n",
      "answer = df_delhi.tail(8)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(msg['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = f\"\"\"\n",
    "{template.split(\"```python\")[1].split(\"```\")[0]}\n",
    "{msg['text'].split(\"```python\")[1].split(\"```\")[0]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to store the error generated in the exec function\n",
    "error = None\n",
    "try:\n",
    "    exec(code)\n",
    "except Exception as e:\n",
    "    error = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleNotFoundError(\"No module named 'pmdarima'\")"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
